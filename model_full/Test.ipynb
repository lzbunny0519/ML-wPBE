{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import rdkit #version 2020.03.5\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.ML.Descriptors import MoleculeDescriptors \n",
    "from padelpy import padeldescriptor #padel linux should be installed.\n",
    "\n",
    "inputfile_smiles='Put_Prediction_File_Here/example.smi' # need to change name\n",
    "\n",
    "#read smiles of molecules \n",
    "file = open(inputfile_smiles)\n",
    "smiles = []\n",
    "for line in file:\n",
    "    if len(line.strip('\\n'))>2:\n",
    "        smiles.append(line.strip('\\n'))\n",
    "file.close()\n",
    "\n",
    "#data for PaDEL\n",
    "try:\n",
    "    padeldescriptor(config='./descriptors.xml',maxruntime=10000,retainorder=True,standardizenitro=True,detectaromaticity=True)\n",
    "    padeldescriptor(mol_dir=inputfile_smiles, d_file='./Put_Prediction_File_Here/PaDEL_FP.csv', fingerprints=True)\n",
    "except:\n",
    "    print('padel have problem')\n",
    "\n",
    "#PaDEL re-order\n",
    "file_Padel_1 = open('./Put_Prediction_File_Here/PaDEL_FP.csv','r')\n",
    "mol_num=[];lines=[]\n",
    "for line in file_Padel_1:\n",
    "    mol_num.append(line.replace('\"', '').split(',')[0].split('_')[-1])\n",
    "    lines.append(line)\n",
    "file_Padel_1.close()\n",
    "\n",
    "file_Padel_2 = open('./Put_Prediction_File_Here/PaDEL_FP.csv','w')\n",
    "for i in range(0,len(lines)):\n",
    "    if i == 0 :\n",
    "        file_Padel_2.write(lines[i])\n",
    "    else:\n",
    "        for j in range(1,len(mol_num)):\n",
    "            if int(i) - int(mol_num[j]) ==0:\n",
    "                file_Padel_2.write(lines[j])\n",
    "                if len(lines[j].replace(',,','').split(',')) < len(lines[0].replace(',,','').split(',')):\n",
    "                    print('line '+str(i)+'have problem!')\n",
    "file_Padel_2.close()\n",
    "\n",
    "\n",
    "#data for RDKit Des\n",
    "mols=[]\n",
    "for i in range(0,len(smiles)):\n",
    "    q=i+1\n",
    "    mols.append(Chem.MolFromSmiles(smiles[i]))   \n",
    "\n",
    "smiles_list = [Chem.MolToSmiles(mol) for mol in mols]\n",
    "descs = [desc_name[0] for desc_name in Descriptors._descList]\n",
    "desc_calc = MoleculeDescriptors.MolecularDescriptorCalculator(descs)\n",
    "descriptors = pd.DataFrame([desc_calc.CalcDescriptors(mol) for mol in mols])\n",
    "descriptors.columns = descs\n",
    "descriptors.index = smiles_list\n",
    "index_list = list(map(str,list(range(len(mols)))))\n",
    "y = pd.DataFrame(index_list)\n",
    "y.index = smiles_list\n",
    "y.columns = [\"index\"]\n",
    "dataset = pd.concat([y, descriptors], axis=1)\n",
    "dataset.to_csv('Put_Prediction_File_Here/Rdkit_Descriptor.csv')\n",
    "\n",
    "#data for RdKit FP\n",
    "with open('Put_Prediction_File_Here/FP_Morgan2.csv', 'w', newline='')as f:\n",
    "    f_csv = csv.writer(f)\n",
    "    for sm_num in range(0,len(smiles)):\n",
    "        bits = []\n",
    "        mol = Chem.MolFromSmiles(smiles[sm_num])\n",
    "        fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius=2, nBits=2048)\n",
    "        bit = fp.ToBitString()\n",
    "        for i in range(0, 2048):\n",
    "            bits.append(bit[i])\n",
    "        f.write(smiles[sm_num])\n",
    "        f.write(',')\n",
    "        f_csv.writerow(bits)\n",
    "        bits.clear()\n",
    "        \n",
    "#Generate data for xtb\n",
    "for i in range(0,len(smiles)):\n",
    "    filename='test'+str(i+1)\n",
    "    newFileBox = 'Put_Prediction_File_Here/xtb/'+str(filename)\n",
    "    m = Chem.MolFromSmiles(smiles[i])\n",
    "    m3d = Chem.AddHs(m)\n",
    "    AllChem.EmbedMolecule(m3d, randomSeed=7)\n",
    "    try:\n",
    "        AllChem.MMFFOptimizeMolecule(m3d,maxIters=100)\n",
    "    except:\n",
    "        print(str(smiles[i])+'optimize fail')\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(newFileBox)\n",
    "    except:\n",
    "        print('already exist')\n",
    "    path1=str(newFileBox)+ '/'+ str(filename) + '.xyz'\n",
    "    f1 = open(path1, 'w')\n",
    "    f1.write(Chem.MolToXYZBlock(m3d))\n",
    "    f1.write(\"$write\\noutput file=properties.out\\n\")\n",
    "    f1.close()\n",
    "    \n",
    "#run xtb\n",
    "for i in range(0,len(smiles)):\n",
    "    filename='test'+str(i+1)\n",
    "    if i == 0: \n",
    "        os.chdir(r'./Put_Prediction_File_Here/xtb/'+str(filename))\n",
    "    else:\n",
    "        os.chdir(r'../'+str(filename))\n",
    "    \n",
    "    os.system('xtb '+str(filename)+'.xyz --opt verytight > xtbout')\n",
    "    os.system('rm  charges xtbopt.log xtbrestart xtbtopo.mol wbo')\n",
    "os.chdir('../../../')\n",
    "\n",
    "#Read xtb output\n",
    "num = []\n",
    "HOMO_fu4_Line=[]\n",
    "HOMO_fu3_Line=[]\n",
    "HOMO_fu2_Line=[]\n",
    "HOMO_fu1_Line=[]\n",
    "HOMO_Line=[]\n",
    "LUMO_Line=[]\n",
    "LUMO_zheng1_Line=[]\n",
    "LUMO_zheng2_Line=[]\n",
    "LUMO_zheng3_Line=[]\n",
    "LUMO_zheng4_Line=[]\n",
    "gap=[]\n",
    "Feimi_level=[]\n",
    "Energy=[]\n",
    "dipole=[]\n",
    "\n",
    "for i in range(0,len(smiles)):\n",
    "    xtb_out_file = 'Put_Prediction_File_Here/xtb/test'+str(i+1)+ '/properties.out'\n",
    "    if os.path.exists(xtb_out_file):\n",
    "        result = open(xtb_out_file)\n",
    "        num.append(i+1)\n",
    "        lines=[]\n",
    "        for line in result:\n",
    "            lines.append(line.strip('\\n'))\n",
    "        result.close()\n",
    "        for hang_line in range(0,len(lines)):\n",
    "            if '(HOMO)' in lines[hang_line]:\n",
    "                HOMO_fu4_Line.append(lines[hang_line-4].split(' ')[-1])\n",
    "                HOMO_fu3_Line .append (lines[hang_line-3].split(' ')[-1])\n",
    "                HOMO_fu2_Line .append (lines[hang_line-2].split(' ')[-1])\n",
    "                HOMO_fu1_Line .append (lines[hang_line-1].split(' ')[-1])\n",
    "                HOMO_Line .append (lines[hang_line].split(' ')[-2])\n",
    "                LUMO_Line .append (lines[hang_line+1].split(' ')[-2])\n",
    "                LUMO_zheng1_Line .append (lines[hang_line+2].split(' ')[-1])\n",
    "                LUMO_zheng2_Line .append (lines[hang_line+3].split(' ')[-1])\n",
    "                LUMO_zheng3_Line .append (lines[hang_line+4].split(' ')[-1])\n",
    "                LUMO_zheng4_Line .append (lines[hang_line+5].split(' ')[-1])\n",
    "                try:\n",
    "                    gap.append (abs(float(lines[hang_line].split(' ')[-2])-float(lines[hang_line+1].split(' ')[-2])))\n",
    "                except:\n",
    "                    gap.append(float(0))\n",
    "            elif 'Fermi-level' in lines[hang_line]:\n",
    "                Feimi_level .append (lines[hang_line].split(' ')[-2])\n",
    "            elif 'TOTAL ENERGY' in lines[hang_line]:\n",
    "                Energy .append (lines[hang_line].split(' ')[-5])\n",
    "            elif 'Debye' in lines[hang_line]:\n",
    "                dipole  .append ( lines[hang_line+2].split(' ')[-1])\n",
    "\n",
    "result_write = open('Put_Prediction_File_Here/SemiL_LRP.csv','w')\n",
    "\n",
    "result_write.write('num,H-4,H-3,H-2,H-1,H,L,L+1,L+2,L+3,L+4,gap,FermiLevel,TotalEnergy,Dipole\\n')\n",
    "\n",
    "for i in range(0,len(num)):\n",
    "    result_write.write(str(num[i]))\n",
    "    result_write.write(','+str(HOMO_fu4_Line[i]))\n",
    "    result_write.write(','+str(HOMO_fu3_Line[i]))\n",
    "    result_write.write(','+str(HOMO_fu2_Line[i]))\n",
    "    result_write.write(','+str(HOMO_fu1_Line[i]))\n",
    "    result_write.write(','+str(HOMO_Line[i]))\n",
    "    result_write.write(','+str(LUMO_Line[i]))\n",
    "    result_write.write(','+str(LUMO_zheng1_Line[i]))\n",
    "    result_write.write(','+str(LUMO_zheng2_Line[i]))\n",
    "    result_write.write(','+str(LUMO_zheng3_Line[i]))\n",
    "    result_write.write(','+str(LUMO_zheng4_Line[i]))\n",
    "    result_write.write(','+str(gap[i]))\n",
    "    result_write.write(','+str(Feimi_level[i]))\n",
    "    result_write.write(','+str(Energy[i]))\n",
    "    result_write.write(','+str(dipole[i]))\n",
    "    result_write.write('\\n')\n",
    "result_write.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib #0.16.0\n",
    "from joblib import dump, load\n",
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import lightgbm as lgb #3.1.1\n",
    "import sklearn #0.23.2\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#inputfile_smiles='Put_Prediction_File_Here/example.smi'\n",
    "\n",
    "#read smiles of molecules \n",
    "file = open(inputfile_smiles)\n",
    "smiles = []\n",
    "for line in file:\n",
    "    if len(line.strip('\\n'))>2:\n",
    "        smiles.append(line.strip('\\n'))\n",
    "file.close()\n",
    "\n",
    "\n",
    "file = open(inputfile_smiles)\n",
    "smiles = []\n",
    "for line in file:\n",
    "    smiles.append(line.strip('\\n'))\n",
    "file.close()\n",
    "# Read Several Files, load as x1(des1), x2(des2), name.\n",
    "def read_file_descriptor(file_path,n=1,startline=1):\n",
    "    x_input = []\n",
    "    jishu=0\n",
    "    with open(file_path, 'r',encoding='utf-8') as f:\n",
    "        f_csv = csv.reader(f)\n",
    "        for row in f_csv:\n",
    "            jishu+=1\n",
    "            if jishu>startline:\n",
    "                x_input.append(row[n:])     \n",
    "    x_input = np.array(x_input)\n",
    "    x_input=x_input.astype('float')\n",
    "    return x_input\n",
    "def read_file_name(file_path):\n",
    "    name=[]\n",
    "    file = open(file_path)\n",
    "    for line in file:\n",
    "        name.append(line.strip('\\n'))\n",
    "    file.close()\n",
    "    return name\n",
    "\n",
    "x_semi = read_file_descriptor(file_path='Put_Prediction_File_Here/SemiL_LRP.csv',n=1,startline=1)\n",
    "scaler = load('wholedataset_Model/scaler.pkl')\n",
    "x_semi = scaler.transform(x_semi)\n",
    "x_des = read_file_descriptor(file_path='Put_Prediction_File_Here/Rdkit_Descriptor.csv',n=2,startline=1)\n",
    "x_Padel = read_file_descriptor(file_path='Put_Prediction_File_Here/PaDEL_FP.csv',n=1,startline=1)\n",
    "x_Padel_part = read_file_descriptor(file_path='Put_Prediction_File_Here/PaDEL_FP.csv',n=2049,startline=1)\n",
    "x_Morgan2 = read_file_descriptor(file_path='Put_Prediction_File_Here/FP_Morgan2.csv',n=1,startline=0)\n",
    "\n",
    "name = smiles\n",
    "x1 = np.concatenate((x_semi,x_Padel_part,x_Morgan2),axis=1)[:,0:]\n",
    "x2 = np.concatenate((x_semi,x_des,x_Padel,x_Morgan2),axis=1)[:,0:]\n",
    "\n",
    "# Load trained model.\n",
    "def load_model_predict(model_file,x_dataset):\n",
    "    reg_layer1 = load(model_file)\n",
    "    x_pre = reg_layer1.predict(x_dataset)\n",
    "    return x_pre\n",
    "\n",
    "x_pre_first_layer=[]\n",
    "print('Predicton Begin')\n",
    "x_pre_first_layer.append(load_model_predict('wholedataset_Model/svr_des1.pkl',x1))\n",
    "x_pre_first_layer.append(load_model_predict('wholedataset_Model/krr_des1.pkl',x1))\n",
    "x_pre_first_layer.append(load_model_predict('wholedataset_Model/Lasso_des1.pkl',x1))\n",
    "x_pre_first_layer.append(load_model_predict('wholedataset_Model/lgb_des2.pkl',x2))\n",
    "x_pre_first_layer.append(load_model_predict('wholedataset_Model/xgboost_des2.pkl',x2))\n",
    "x_pre_first_layer.append(load_model_predict('wholedataset_Model/GBRT_des2.pkl',x2))\n",
    "x_pre_first_layer.append(load_model_predict('wholedataset_Model/Lasso_des2.pkl',x2))\n",
    "x_pre_first_layer.append(load_model_predict('wholedataset_Model/RF_des2.pkl',x2))\n",
    "print('Prediction Finish')\n",
    "\n",
    "x_pre_first_layer_T=list(zip(*x_pre_first_layer))\n",
    "x_pre_first_layer_T = np.array(x_pre_first_layer_T)\n",
    "\n",
    "reg_second_layer = load('wholedataset_Model/Lars_secondlayer.pkl')\n",
    "x_pre_second_layer = reg_second_layer.predict(x_pre_first_layer_T)\n",
    "\n",
    "for i in range(0,len(name)):\n",
    "    print(round(x_pre_second_layer[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
